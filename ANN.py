# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sd_cMV5HwVZ7AHop2Baqdk5MHWKozDmS
"""

import pandas as pd

import pandas as pd

df=pd.read_csv('http://13.234.66.67/summer19/datasets/bank.csv')

df.head()

features=df.iloc[:,3:13].values

label=df.iloc[:,13]

label.shape

from sklearn.preprocessing import LabelEncoder,OneHotEncoder

lbc=LabelEncoder()

# for geo

features[:,1]=lbc.fit_transform(features[:,1])
features.shape

features[:,2]=lbc.fit_transform(features[:,2])
features.shape

features

# creating dummy var
one=OneHotEncoder(categorical_features=[1])

features=one.fit_transform(features).toarray()
features1=features[:,1:]
features1.shape

# trianing and testing 
from sklearn.model_selection import train_test_split

X,x,Y,y=train_test_split(features1,label,test_size=0.2)

# features scaling 
from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

# training data scale 
sc.fit_transform(X)

# testing data trqnsform 
x=sc.transform(x)

X.shape



"""now we can create ANN model"""

import keras   #this is the way of using tensorflow in background

# keras ANN model library import 
from keras.models import Sequential

# fitting data in each layer
from keras.layers import Dense
# this will give the method to decide activation function and number of nodes in each layer
# including input ,hidden and output layer

# now we can design Model 
model=Sequential()

# now we can add input layer 
model.add(Dense(6,input_shape=(11,),activation='relu'))
# relu --means rectifier activation Function

# adding one more hidden layer 
model.add(Dense(6,activation='relu'))
# note we don't have to assign number of inputs after first /input layer

# final layer adding 
model.add(Dense(1,activation='sigmoid'))

# compile 
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
# optimizer -- weight adjust method --stochitis g d (adam)

# training data fit 
  model.fit(X,Y,batch_size=2000,epochs=100)

model.predict(x)   # now prediction test data



# accuracy -- confusion matrix